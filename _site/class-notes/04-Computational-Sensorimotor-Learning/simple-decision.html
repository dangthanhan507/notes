<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/blog/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/blog/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav > ul.nav-list:first-child > li > a, .site-nav > ul.nav-list:first-child > li > ul > li > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li:not(:nth-child(1)) > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li > ul > li a { background-image: none; } .site-nav > ul.nav-list:not(:first-child) a, .site-nav li.external a { background-image: none; } .site-nav > ul.nav-list:first-child > li:nth-child(3) > ul > li:nth-child(5) > ul > li:nth-child(1) > a { font-weight: 600; text-decoration: none; }.site-nav > ul.nav-list:first-child > li:nth-child(3) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(3) > ul > li:nth-child(5) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(3) > ul > li:nth-child(5) > ul > li:nth-child(1) > button svg { transform: rotate(-90deg); }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(3) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(3) > ul.nav-list > li.nav-list-item:nth-child(5) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(3) > ul.nav-list > li.nav-list-item:nth-child(5) > ul.nav-list > li.nav-list-item:nth-child(1) > ul.nav-list { display: block; } </style> <script src="/blog/assets/js/vendor/lunr.min.js"></script> <script src="/blog/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Simple Decisions | Notes</title> <meta name="generator" content="Jekyll v4.2.2" /> <meta property="og:title" content="Simple Decisions" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Just messing around right now" /> <meta property="og:description" content="Just messing around right now" /> <link rel="canonical" href="http://localhost:4000/blog/class-notes/04-Computational-Sensorimotor-Learning/simple-decision.html" /> <meta property="og:url" content="http://localhost:4000/blog/class-notes/04-Computational-Sensorimotor-Learning/simple-decision.html" /> <meta property="og:site_name" content="Notes" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Simple Decisions" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"Just messing around right now","headline":"Simple Decisions","url":"http://localhost:4000/blog/class-notes/04-Computational-Sensorimotor-Learning/simple-decision.html"}</script> <!-- End Jekyll SEO tag --> <link rel="icon" href="data:,"> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } } }); </script> <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML"> </script> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/blog/" class="site-title lh-tight"> Notes </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Code Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/" class="nav-list-link">Code Notes</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/code-notes/how-to-pdb.html" class="nav-list-link">How-to PDB</a></li><li class="nav-list-item"><a href="/blog/code-notes/how-to-tmux.html" class="nav-list-link">How-to Tmux</a></li><li class="nav-list-item"><a href="/blog/code-notes/distributed-dl.html" class="nav-list-link">Distributed Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/image-augmentation.html" class="nav-list-link">Image Augmentation (Torchvision)</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Benchmarks category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/benchmark-notes/" class="nav-list-link">Benchmarks</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Robocasa category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/benchmark-notes/robocasa/" class="nav-list-link">Robocasa</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/code-notes/benchmark-notes/robocasa/paper.html" class="nav-list-link">Paper</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Libero category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/benchmark-notes/libero/" class="nav-list-link">Libero</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/code-notes/benchmark-notes/libero/paper.html" class="nav-list-link">Paper</a></li><li class="nav-list-item"><a href="/blog/code-notes/benchmark-notes/libero/code.html" class="nav-list-link">Code</a></li></ul></li><li class="nav-list-item"><a href="/blog/code-notes/benchmark-notes/robomimic.html" class="nav-list-link">Robomimic</a></li></ul></li><li class="nav-list-item"><a href="/blog/code-notes/python-env.html" class="nav-list-link">Python Environments</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in GROOT category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/groot/" class="nav-list-link">GROOT</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/code-notes/groot/code.html" class="nav-list-link">Code</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Isaac category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/isaac/" class="nav-list-link">Isaac</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/code-notes/isaac/setup.html" class="nav-list-link">Isaac Setup</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/doc_notes.html" class="nav-list-link">Isaac Gym Doc Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/gymenv-obs.html" class="nav-list-link">IsaacGymEnv Obs Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/gymenv-cam.html" class="nav-list-link">IsaacGymEnv Camera Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/gymenv-network.html" class="nav-list-link">IsaacGymEnv Network Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/gymenv-tacsl.html" class="nav-list-link">IsaacGymEnv Tacsl Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/gymenv-assets.html" class="nav-list-link">IsaacGymEnv Assets Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/gymenv-env.html" class="nav-list-link">IsaacGymEnv Env Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/gymenv-task.html" class="nav-list-link">IsaacGymEnv Task Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/rl_games_integration.html" class="nav-list-link">RL Games Coupling</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/setup_isaacgymenvs.html" class="nav-list-link">IsaacGymEnvs Setup</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Cluster Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/cluster-notes/" class="nav-list-link">Cluster Notes</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/code-notes/cluster-notes/great-lakes.html" class="nav-list-link">Great Lakes Cluster</a></li><li class="nav-list-item"><a href="/blog/code-notes/cluster-notes/slurm-interactive.html" class="nav-list-link">SLURM Interactive</a></li><li class="nav-list-item"><a href="/blog/code-notes/cluster-notes/slurm.html" class="nav-list-link">SLURM</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Isaac Lab category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/isaaclab/" class="nav-list-link">Isaac Lab</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/code-notes/isaaclab/setup.html" class="nav-list-link">Isaac Lab Setup</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaaclab/isaacsim-start.html" class="nav-list-link">Isaac Sim Python Start</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaaclab/isaacsim-hello-world.html" class="nav-list-link">IsaacSim Core (Hello World)</a></li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Conference Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/conference-notes/" class="nav-list-link">Conference Notes</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in ICRA 2025 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/conference-notes/icra-2025/" class="nav-list-link">ICRA 2025</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/workshop/beyond-pick-place.html" class="nav-list-link">Beyond Pick and Place Workshop</a></li><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/workshop/contact-rich.html" class="nav-list-link">Contact Rich Workshop</a></li><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/workshop/handy.html" class="nav-list-link">Handy Workshop</a></li><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/homework.html" class="nav-list-link">Homework</a></li><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/keynote-manipulation.html" class="nav-list-link">Manipulation Keynote</a></li><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/keynote-opt.html" class="nav-list-link">Optimization Control Keynote</a></li><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/workshop/neuro-symbolic.html" class="nav-list-link">Neuro-Symbolic Workshop</a></li><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/workshop/space.html" class="nav-list-link">Space Workshop</a></li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Class Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/class-notes/" class="nav-list-link">Class Notes</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in MATH 658: Geometric Mechanics category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/class-notes/00-Geometric-Mechanics/" class="nav-list-link">MATH 658: Geometric Mechanics</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in 658-Lectures category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/class-notes/00-Geometric-Mechanics/Lectures/" class="nav-list-link">658-Lectures</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/class-notes/00-Geometric-Mechanics/Lectures/08-27.html" class="nav-list-link">August 27</a></li><li class="nav-list-item"><a href="/blog/class-notes/00-Geometric-Mechanics/Lectures/09-03.html" class="nav-list-link">September 3</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Textbook category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/class-notes/00-Geometric-Mechanics/Textbook/" class="nav-list-link">Textbook</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/class-notes/00-Geometric-Mechanics/Textbook/diff-manifold.html" class="nav-list-link">Differentiable Manifold (2.2)</a></li><li class="nav-list-item"><a href="/blog/class-notes/00-Geometric-Mechanics/Textbook/variational-mech.html" class="nav-list-link">Variational Mechanics (1.2 - 1.3)</a></li><li class="nav-list-item"><a href="/blog/class-notes/00-Geometric-Mechanics/Textbook/vector-fields.html" class="nav-list-link">Vector Fields (2.1)</a></li></ul></li></ul></li><li class="nav-list-item"><a href="/blog/class-notes/01-Math-of-Bio-Networks/" class="nav-list-link">MATH 540: Mathematics for Biological Networks</a></li><li class="nav-list-item"><a href="/blog/class-notes/02-Online-Learning-Control/" class="nav-list-link">AEROSP 740: Online Learning for Control</a></li><li class="nav-list-item"><a href="/blog/class-notes/03-CVOPT-Control/" class="nav-list-link">ECE 598: Convex Optimization Methods in Control</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Sensorimotor Learning category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/class-notes/04-Computational-Sensorimotor-Learning/" class="nav-list-link">Sensorimotor Learning</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/class-notes/04-Computational-Sensorimotor-Learning/simple-decision.html" class="nav-list-link">1. Simple Decisions</a></li><li class="nav-list-item"><a href="/blog/class-notes/04-Computational-Sensorimotor-Learning/sequential-decision.html" class="nav-list-link">2. Sequential Decisions</a></li><li class="nav-list-item"><a href="/blog/class-notes/04-Computational-Sensorimotor-Learning/policy-grad.html" class="nav-list-link">3. Policy Gradients</a></li><li class="nav-list-item"><a href="/blog/class-notes/04-Computational-Sensorimotor-Learning/reward-function.html" class="nav-list-link">4. Reward Function</a></li><li class="nav-list-item"><a href="/blog/class-notes/04-Computational-Sensorimotor-Learning/learning-from-demo.html" class="nav-list-link">5. Learning Demos</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Unsupervised Learning category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/class-notes/05-Unsupervised-Learning/" class="nav-list-link">Unsupervised Learning</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/1_autoregressive.html" class="nav-list-link">1. Autoregressive</a></li><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/2_flow.html" class="nav-list-link">2. Flow</a></li><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/3_lvm.html" class="nav-list-link">3. Latent Variable Models</a></li><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/3a_lvm.html" class="nav-list-link">3a. LVM Papers</a></li><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/4_implicit_sample.html" class="nav-list-link">4. Implicit Models</a></li><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/5_diffusion.html" class="nav-list-link">5. Diffusion</a></li><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/5a_diffusion.html" class="nav-list-link">5a. Diffusion Papers</a></li><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/6_self_supervised.html" class="nav-list-link">6. Self-Supervised Learning</a></li></ul></li><li class="nav-list-item"><a href="/blog/class-notes/06-Flow-Matching/" class="nav-list-link">Flow Matching and Diffusion</a></li><li class="nav-list-item"><a href="/blog/class-notes/07-Deep-RL/" class="nav-list-link">Deep Reinforcement Learning</a></li><li class="nav-list-item"><a href="/blog/class-notes/08-Deep-Multitask-Learning/" class="nav-list-link">Deep Multi-Task and Meta Learning</a></li><li class="nav-list-item"><a href="/blog/class-notes/09-Algebraic-Techniques-Optimization/" class="nav-list-link">Algebraic Techniques for Optimization</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Deep Dive Ideas category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/deep-dive-notes/" class="nav-list-link">Deep Dive Ideas</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Debug Point ML category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/deep-dive-notes/debug-point-ml/" class="nav-list-link">Debug Point ML</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/deep-dive-notes/debug-point-ml/pointnet.html" class="nav-list-link">PointNet</a></li><li class="nav-list-item"><a href="/blog/deep-dive-notes/debug-point-ml/spatial-transformer.html" class="nav-list-link">Spatial Transformer Networks</a></li></ul></li><li class="nav-list-item"><a href="/blog/deep-dive-notes/limit-surface/" class="nav-list-link">Limit Surface Planner</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Tactile RL Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/deep-dive-notes/tactile-rl-notes/" class="nav-list-link">Tactile RL Notes</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/deep-dive-notes/tactile-rl-notes/fots.html" class="nav-list-link">FOTS</a></li><li class="nav-list-item"><a href="/blog/deep-dive-notes/tactile-rl-notes/roadmap-rl.html" class="nav-list-link">Roadmap to RL</a></li><li class="nav-list-item"><a href="/blog/deep-dive-notes/tactile-rl-notes/roadmap-tactile-rl.html" class="nav-list-link">Roadmap to Tactile RL</a></li><li class="nav-list-item"><a href="/blog/deep-dive-notes/tactile-rl-notes/sim2real-tactile-rl.html" class="nav-list-link">Sim2real Tactile RL</a></li><li class="nav-list-item"><a href="/blog/deep-dive-notes/tactile-rl-notes/tacsl.html" class="nav-list-link">TacSL</a></li><li class="nav-list-item"><a href="/blog/deep-dive-notes/tactile-rl-notes/taxim.html" class="nav-list-link">Taxim</a></li></ul></li></ul></li><li class="nav-list-item"><a href="/blog/paper-notes/" class="nav-list-link">Deep Dive Papers</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Judo Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/judo-notes/" class="nav-list-link">Judo Notes</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/judo-notes/taught.html" class="nav-list-link">Taught Moves</a></li><li class="nav-list-item"><a href="/blog/judo-notes/tolearn.html" class="nav-list-link">To Learn</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Kuka FRI Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/kuka-notes/" class="nav-list-link">Kuka FRI Notes</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/kuka-notes/code.html" class="nav-list-link">Code</a></li><li class="nav-list-item"><a href="/blog/kuka-notes/setup.html" class="nav-list-link">Setup FRI</a></li></ul></li><li class="nav-list-item"><a href="/blog/ml-git-gud-notes/" class="nav-list-link">ML (Git Gud) Resources</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in PhD Project Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/project-notes/" class="nav-list-link">PhD Project Notes</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/project-notes/hand-notes.html" class="nav-list-link">Hand Notes</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Graph Insertion category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/project-notes/project1/" class="nav-list-link">Graph Insertion</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Lit Review (Graph Insertion) category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/project-notes/project1/lit_review/" class="nav-list-link">Lit Review (Graph Insertion)</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/project-notes/project1/lit_review/robopack.html" class="nav-list-link">Robopack</a></li><li class="nav-list-item"><a href="/blog/project-notes/project1/lit_review/tactile-control-extrinsic.html" class="nav-list-link">Extrinsic Contact Control</a></li></ul></li><li class="nav-list-item"><a href="/blog/project-notes/project1/math.html" class="nav-list-link">Math Notes</a></li><li class="nav-list-item"><a href="/blog/project-notes/project1/project.html" class="nav-list-link">Point RL</a></li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Prerequisites category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/prereq-notes/" class="nav-list-link">Prerequisites</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/prereq-notes/calc-variation.html" class="nav-list-link">Calculus of Variations - Chill</a></li><li class="nav-list-item"><a href="/blog/prereq-notes/calc-variation2.html" class="nav-list-link">Calculus of Variations - Serious</a></li><li class="nav-list-item"><a href="/blog/prereq-notes/groups.html" class="nav-list-link">GDL 1: Groups</a></li><li class="nav-list-item"><a href="/blog/prereq-notes/topology.html" class="nav-list-link">GDL 2: Topology</a></li><li class="nav-list-item"><a href="/blog/prereq-notes/manifolds.html" class="nav-list-link">GDL 3: Manifolds</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Quick Notes on Graphs category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/graph-notes/" class="nav-list-link">Quick Notes on Graphs</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/graph-notes/advective-diff.html" class="nav-list-link">Advective Diffusion</a></li><li class="nav-list-item"><a href="/blog/graph-notes/beyond-wl.html" class="nav-list-link">Beyond WL-test</a></li><li class="nav-list-item"><a href="/blog/graph-notes/wl-test-gnn.html" class="nav-list-link">GNN WL-test</a></li><li class="nav-list-item"><a href="/blog/graph-notes/gnn-grad-flow.html" class="nav-list-link">GNN as Gradient Flow</a></li><li class="nav-list-item"><a href="/blog/graph-notes/gnn-pde.html" class="nav-list-link">GNNs as PDEs</a></li><li class="nav-list-item"><a href="/blog/graph-notes/graph-rewiring.html" class="nav-list-link">Graph Rewiring</a></li><li class="nav-list-item"><a href="/blog/graph-notes/latent-gnn.html" class="nav-list-link">Latent GNNs</a></li><li class="nav-list-item"><a href="/blog/graph-notes/neural-sheaf-diffusion.html" class="nav-list-link">Neural Sheaf Diffusion</a></li><li class="nav-list-item"><a href="/blog/graph-notes/deep-gnn.html" class="nav-list-link">Scaling GNNs</a></li><li class="nav-list-item"><a href="/blog/graph-notes/temporal-gnn.html" class="nav-list-link">Temporal GNNs</a></li></ul></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Notes" aria-label="Search Notes" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/blog/class-notes/">Class Notes</a></li> <li class="breadcrumb-nav-list-item"><a href="/blog/class-notes/04-Computational-Sensorimotor-Learning/">Sensorimotor Learning</a></li> <li class="breadcrumb-nav-list-item"><span>1. Simple Decisions</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h1 id="1-simple-decision-making"> <a href="#1-simple-decision-making" class="anchor-heading" aria-labelledby="1-simple-decision-making"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1. Simple Decision Making </h1> <h2 id="11-multi-armed-bandit-mab"> <a href="#11-multi-armed-bandit-mab" class="anchor-heading" aria-labelledby="11-multi-armed-bandit-mab"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.1 Multi-armed Bandit (MAB) </h2> <p>This is a simple reward-based learning problem where you have to choose one out of K possible actions (discrete).</p> <p>The MAB setup assumes that rewards are independent of the state and history of actions (not like how I’m used to in control). Reward depends on current action:</p> \[\begin{equation} r(a_t) = r(a_{1:t}, s_{1:t}) \end{equation}\] <p>The goal is to construct a policy that maximizes reward over horizon of T time steps:</p> \[\begin{equation} \sum_{t=1}^T r_t(a_t) \end{equation}\] <h2 id="11a-webpage-example"> <a href="#11a-webpage-example" class="anchor-heading" aria-labelledby="11a-webpage-example"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.1a Webpage example </h2> <p>Say we want to build a recommendation system for landing webpages. Our goal is to build a recommendation system that displays the landing page that maximizes profit. <b> NOTE: </b> We have no priors on which landing page maximizes profit.</p> <p>Assume the following:</p> <ul> <li>\(T\) - <b> Horizon </b></li> <li>\(t\) - <b> time step </b> or i-th user visiting a page</li> <li>\(E\) - <b> environment </b> (website)</li> <li>\(A\) - <b> agent </b> (recommendation system)</li> <li>\(\mathcal{A} := \{1,...,K\}\) - <b> action space </b> where \(K\) is the number of pages and \(k \in [1,K]\) correspond to the action of recommending i-th page.</li> <li>\(a_t\) - <b> action </b> at round t where \(a_t \in \mathcal{A}, \forall t \in [1, T]\)</li> <li>\(r_t(a_t) \in \mathbb{R}\) - <b> reward </b> (random variable) which is profit earned by displaying page.</li> <li>\(T_k(t)\) - <b> action count </b>. number of times that action \(k\) has been taken within \(t\) rounds.</li> <li>\(\mu_k\) - <b> True mean reward </b> of taking action \(k\). This optimal mean reward is defined as \(\mu^* = \max_k \mu_k\).</li> <li>\(\hat \mu_k(t)\) - <b> empirical mean reward </b> of taking action \(k\), estimated by our algorithm over \(t\) rounds.</li> </ul> \[\begin{equation} \hat \mu_k(t) := \frac{1}{T_k(t)} \sum_{t=1}^T \mathbb{I}\{a_t = k\}r(a_t) \end{equation}\] <p>where \(\mathbb{I}\) is the indicator function. This means that when \(k\) is chosen, the empirical mean reward is the average of the profit of the pages displayed from \(1\) to \(T\).</p> <p>We formulate maximizing profit as:</p> \[\begin{equation} \max_{a_1,...,a_T} \mathbb{E} [\sum_{t=1}^T r(a_t)] \end{equation}\] <p>Exploration and exploitation is the balance between trying new actions (exploration) and using the best action (exploitation).</p> <p><b> Definition 1.1 </b> (Exploration). We define any action selection \(a\) such that:</p> \[\require{cancel} \begin{align} \hat \mu_a(t) &amp;\cancel{=} \max_{k} \hat \mu_k(t) \\ \hat \mu_a(t) &amp;\cancel{=} \max_{k} \frac{1}{T_k(t)} \sum_{t=1}^T \mathbb{I}\{a_t = k \}r(a_t) \end{align}\] <p>as exploration. We are taking actions that are not the actions that maximizes the empirical mean reward. <b> NOTE: </b> this is not the same as the true mean reward.</p> <p><b> Definition 1.2 </b> (Exploitation). We define any action selection \(a\) such that:</p> \[\begin{equation} \hat \mu_a(t) = \max_{k} \hat \mu_k(t) \end{equation}\] <p>as exploitation. We are taking actions that maximize the empirical mean reward.</p> <p>Our goal is to try to align \(\hat \mu_a\) and \(\mu_a\), \(\forall a \in \mathcal{A}\). To do this, we have to get samples of \(r(a)\) to improve accuracy of empirical mean reward (exploration).</p> <p>Performance of an algorithm on balancing exploration and exploitation is measured by regret. In plain language, regret means “loss incurred by past actions”. It characterizes gap between optimal expected reward and expected reward obtained by our algorithm. Regret over \(T\) time steps is formally denoted as:</p> \[\begin{equation} \textbf{Regret}(T) = T\mu^* - \mathbb{E}[\sum_{t=1}^T r(a_t)] \end{equation}\] <p>where the expectation is taken over multiple episodes of T rounds.</p> <p>We can design MAB to minimize regret:</p> \[\begin{equation} \min_{a_1,...,a_T} T\mu^* - \mathbb{E}[\sum_{t=1}^T r(a_t)] \end{equation}\] <p>Minimizing regret is equivalent to maximizing rewards. Why use regret then? It actually has better theoretical properties to analyze trade-offs between exploration and exploitation.</p> <h2 id="111-explore-then-commit-etc"> <a href="#111-explore-then-commit-etc" class="anchor-heading" aria-labelledby="111-explore-then-commit-etc"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.1.1 Explore-then-commit (ETC) </h2> <p>Let rewards be deterministic. Optimal strategy is try every action space once and then choose action with highest reward for all time steps in the future.</p> <p>In stochastic settings, we try each action multiple times to get a good estimate of the reward.</p> <p>Assume each action is attempted \(m\) times. Afterwards, the agent chooses to execute the optimal action with highest empirical mean reward. This is ETC. There is a distinct explore phase and exploit phase. We spend \(mK\) time steps on exploration and \(T - mK\) time steps on exploitation.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ETC</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;=</span> <span class="n">mK</span><span class="p">:</span>
        <span class="n">at</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span> <span class="o">%</span> <span class="n">K</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">at</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span> <span class="p">[</span><span class="n">muhat</span><span class="p">(</span><span class="n">mK</span><span class="p">,</span> <span class="n">a_k</span><span class="p">)</span> <span class="k">for</span> <span class="n">a_k</span> <span class="ow">in</span> <span class="n">action_space</span><span class="p">]</span> <span class="p">)</span>
    <span class="k">return</span> <span class="n">at</span>
</code></pre></div></div> <p>This is the ETC policy. Note that <code class="language-plaintext highlighter-rouge">muhat</code> is the empirical mean reward that changes after each call of ETC function during the exploration phase.</p> <p><b> How good is it? </b> The regret of ETC is bounded by:</p> \[\begin{equation} \textbf{Regret}(T) \leq m \sum_{k=1}^K \Delta_k + (T - mK) \sum_{k=1}^K \Delta_k \text{exp}(-\frac{m\Delta_k^2}{4}) \end{equation}\] <p>where \(\Delta_k = \mu^* - \mu_k\) is the gap between the optimal action and the action \(k\).</p> <p>This regret is split into the exploration and exploitation regret. The first term is the regret incurred during exploration and the second term is the regret incurred during exploitation.</p> <p>So now we can see analyze the regret of the algorithm using big-O notation. Typically \(m := T^{\frac{2}{3}}\), thus:</p> \[\begin{equation} \textbf{Regret}(T) \leq \text{O}(KT^{\frac{2}{3}}) \end{equation}\] <p>This is better than worst regret \(\text{O}(T)\) (linear). Worst regret is obtained if agent chooses suboptimal actions or randomly selects actions through T rounds.</p> <h2 id="112-upper-confidence-bound-ucb"> <a href="#112-upper-confidence-bound-ucb" class="anchor-heading" aria-labelledby="112-upper-confidence-bound-ucb"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.1.2 Upper Confidence Bound (UCB) </h2> <p>The ETC exploration is “unguided”. We select actions uniformly at random. If we are already certain about expected reward of an action, we should not explore it. This means we have to model uncertainty for each action to take the most promising action for exploration.</p> <p><b> Upper Confidence Bound (UCB) </b> constructs uncertainty of actions using confidence bounds of mean reward. It employs “optimism in the face of uncertainty” principle. This principle states that we should overestimate the expected reward of actions that we are uncertain about.</p> <p>We want to construct \(\hat \mu_k'\) such that \(\hat \mu_k' \geq \mu_k\). Finding such \(\hat \mu_k'\) can be intractable since we do not know \(\mu_k\).</p> <p>If we assume \(r(a_t)\) is drawn from a 1-subgaussian distribution, we can construct \(\hat \mu_k\) probabilistically.</p> <p>Remember that \(\mu_k\) is the mean reward. Thus the following inequality holds:</p> \[\begin{equation} P(\mu_k \geq \hat \mu_k + \epsilon) \leq \text{exp}(-\frac{T_k(t)\epsilon^2}{2}), \epsilon \geq 0 \end{equation}\] <p>Equivalently, solving for \(\epsilon\) when equality holds, we transform the inequality to:</p> \[\begin{equation} P(\hat \mu_k \geq \hat \mu_k + \sqrt{\frac{2 \log \frac{1}{\delta}}{T_k(t)}}) \leq \delta, \delta \in (0,1) \end{equation}\] <p>As a result, \(\hat \mu_k\) can be constructed by:</p> \[\begin{equation} \hat \mu_k' = \hat \mu_k + \sqrt{\frac{2\log \frac{1}{\delta}}{T_k(t)}} \end{equation}\] <p>This \(\hat \mu_k'\) is the upper confidence bound of the empirical mean reward since \(\sqrt{\frac{2\log \frac{1}{\delta}}{T_k(t)}}\) is a non-negative term. This means that the upper confidence bound holds with at least \(1 - \delta\) probability.</p> <p>As \(\delta\) increases, the term \(\sqrt{\frac{2\log \frac{1}{\delta}}{T_k(t)}}\) decreases. This means that the upper bound gap decreases as the likelihood of it holding increases. We refer to \(delta\) as the <b> confidence level </b>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">UCB</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
    <span class="n">at</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span> <span class="p">[</span><span class="n">muhat</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">a_k</span><span class="p">)</span> <span class="o">+</span> <span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">delta</span><span class="p">)</span><span class="o">/</span><span class="n">T_k</span><span class="p">(</span><span class="n">t</span><span class="p">))</span> <span class="k">for</span> <span class="n">a_k</span> <span class="ow">in</span> <span class="n">action_space</span><span class="p">]</span> <span class="p">)</span>
    <span class="k">return</span> <span class="n">at</span>
</code></pre></div></div> <p>We need to make sure that setting \(\delta\) ensures that the second term \(\sqrt{\frac{2\log \frac{1}{\delta}}{T_k(t)}}\) disappears as \(t\) increases. This is the regret analysis of UCB when \(\delta = \frac{1}{t^2}\).:</p> \[\begin{equation} \textbf{Regret}(T) \leq 8(\sum_{k=2}^K \frac{\log T}{\Delta_k}) + (1 + \frac{\pi^3}{3})(\sum_{k=1}^K \Delta_k) \end{equation}\] <p>where without loss of generality, we let \(\mu_1 = \mu^*\) for simplicity. The big-O notation of this is:</p> \[\begin{equation} \textbf{Regret}(T) \leq \text{O}(\sqrt{KT\log T}) \end{equation}\] <p>which is much tighter than ETC.</p> <h2 id="12-contextual-bandit-cb"> <a href="#12-contextual-bandit-cb" class="anchor-heading" aria-labelledby="12-contextual-bandit-cb"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.2 Contextual Bandit (CB) </h2> <p>Before, we considered a special case where the reward was independent of the state. In CB, we assume that reward is state (or context) dependent.</p> <p>Now the reward is:</p> \[\begin{equation} r(a_t, s_t) = r(a_{1:t}, s_{1:t}) \end{equation}\] <p>We consider the next following concepts related to CB which are augmented from MAB:</p> <ul> <li><b> Context </b> \(x_t\): this is the state where \(x_t \in \mathcal{X}\) where \(\mathcal{X}\) is the context/state space.</li> <li><b> Contextual Reward </b> \(r(a_t, x_t) \in \mathbb{R}\): this is the reward of taking action \(a_t\) in context \(x_t\).</li> <li><b> Contextual expected regret </b> \(\textbf{Regret}(T)\) expressed as:</li> </ul> \[\begin{equation} \textbf{Regret}(T) := \mathbb{E}[\sum_{t=1}^T \max_{a \in \mathcal{A}} r(x_t, a) - r(x_t, a_t)] \end{equation}\] <p>now how do we choose actions in CB? We can use the same principles as MAB.</p> <h2 id="121-linucb"> <a href="#121-linucb" class="anchor-heading" aria-labelledby="121-linucb"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.2.1 LinUCB </h2> <p>LinUCB is a linear contextual bandit algorithm. It assumes that the reward is linear in the context.</p> <p>First-pass we can try to make UCB context-dependent:</p> \[\begin{equation} \hat \mu_{x,k}(t) := \frac{1}{T_{x,k}(t)} \sum_{t=1}^T \mathbb{I}\{a_t=k, x_t=x\}r(x_t,a_t) \end{equation}\] <p>How do we obtain \(T_{x,k}(t)\) without knowing \(\mathcal{X}\)? If we cannot enumerate through \(\mathcal{X}\), there will be infinite elements for \(T_{x,k}(t)\). We need to get around this issue. This is the motivation for LinUCB.</p> <p>The key idea of LinUCB is to estimate context-dependent empirical mean and and confidence interval by linear regression. Let context \(x \in \mathbb{R}^d\). We use LinUCB implementation with disjoint linear models. Let \(\hat \theta_k \in \mathbb{R}^d\) be the parameter vector for linear regression.</p> \[\begin{equation} \hat \mu_{\hat \theta_k}(x) := \hat \theta_k^T x \end{equation}\] <p>which is a scalar term.</p> <p><b> Empirical mean </b> Rewards are assumed to be drawn from a 1-subgaussian distribution. We use least-squares to get the parameter vector:</p> \[\begin{equation} \hat \theta_k^* = \arg \min_{\hat \theta_k} \mathbb{E} [(\hat \mu_{\hat \theta_k}(x) - r(x, k))^2] \end{equation}\] <p>this approximates the mean of the gaussian distribution. This can be solved in closed form using the following equation:</p> \[\begin{equation} \hat \theta_k^* = (\mathbf{D}_k^T\mathbf{D}_k + \lambda \mathbf{I})^{-1} \mathbf{D}^T_k \mathbf{c}_k \end{equation}\] <p>This is the closed form solution for linear regression but there is an added term \(\lambda \mathbf{I}\). This is a regularization term that prevents overfitting (ridge regression).</p> <p><b> Confidence bound </b> We cannot directly construct a confidence bound because we cannot calculate \(T_{x,k}(t)\). A workaround is needed to construct this bound:</p> \[\begin{equation} P(\mu_{x,k} \geq \hat \mu_{\hat \theta_k}(\mathbf{x}_{t,k}) + \alpha \sqrt{\mathbf{x}_{t,k}^T(\mathbf{D}_k^T\mathbf{D}_k + \lambda \mathbf{I})^{-1}\mathbf{x}_{t,k}}) \leq \delta, \delta \in (0,1) \end{equation}\] <p>where \(\alpha := 1 + \sqrt{\frac{\log\frac{2}{\delta}}{2}}\).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">LinUCB</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="k">lambda</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">x_tk</span> <span class="o">=</span> <span class="n">receive_contexts</span><span class="p">()</span>
    <span class="n">d</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_tk</span><span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">action_space</span><span class="p">)):</span>
        <span class="n">ak</span> <span class="o">=</span> <span class="n">action_space</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">ak</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">taken_ks</span><span class="p">:</span> 
            <span class="n">A_k</span> <span class="o">=</span> <span class="k">lambda</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">eye</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
            <span class="n">b_k</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
            <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">A_k</span>
            <span class="n">b</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">b_k</span>
            <span class="n">taken_ks</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">ak</span><span class="p">)</span>
        <span class="n">theta_k</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">@</span> <span class="n">b</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="n">theta</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">theta_k</span><span class="p">)</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="n">delta</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">at</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span> <span class="p">[</span><span class="n">theta</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">@</span> <span class="n">x_tk</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">x_tk</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="o">@</span> <span class="n">x_tk</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">action_space</span><span class="p">]</span> <span class="p">)</span>

    <span class="c1"># modify A, b for next calls of LinUCB
</span>    <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">outer</span><span class="p">(</span><span class="n">x_tk</span><span class="p">,</span> <span class="n">x_tk</span><span class="p">)</span>
    <span class="n">b</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">b</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">r</span><span class="p">(</span><span class="n">x_tk</span><span class="p">,</span> <span class="n">at</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_tk</span>
    <span class="k">return</span> <span class="n">at</span>
</code></pre></div></div> </main> <hr> <footer> <p class="text-small text-grey-dk-100 mb-0">By An Dang.</p> <div class="d-flex mt-2"> <p class="text-small text-grey-dk-000 mb-0"> <a href="https://github.com/dangthanhan507/dangthanhan507.github.io/blob/master/class-notes/04-Computational-Sensorimotor-Learning/simple-decision.md" id="edit-this-page">Edit this page on GitHub.</a> </p> </div> </footer> </div> </div> <div class="search-overlay"></div> </div> <script type="module"> import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.6.0/dist/mermaid.esm.min.mjs'; var config = {} ; mermaid.initialize(config); mermaid.run({ querySelector: '.language-mermaid', }); </script> </body> </html>
