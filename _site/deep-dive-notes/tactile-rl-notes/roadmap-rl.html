<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/blog/assets/css/just-the-docs-default.css"> <link rel="stylesheet" href="/blog/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"> <style id="jtd-nav-activation"> .site-nav > ul.nav-list:first-child > li > a, .site-nav > ul.nav-list:first-child > li > ul > li > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li:not(:nth-child(2)) > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li > ul > li a { background-image: none; } .site-nav > ul.nav-list:not(:first-child) a, .site-nav li.external a { background-image: none; } .site-nav > ul.nav-list:first-child > li:nth-child(4) > ul > li:nth-child(3) > ul > li:nth-child(2) > a { font-weight: 600; text-decoration: none; }.site-nav > ul.nav-list:first-child > li:nth-child(4) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(4) > ul > li:nth-child(3) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(4) > ul > li:nth-child(3) > ul > li:nth-child(2) > button svg { transform: rotate(-90deg); }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(4) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(4) > ul.nav-list > li.nav-list-item:nth-child(3) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(4) > ul.nav-list > li.nav-list-item:nth-child(3) > ul.nav-list > li.nav-list-item:nth-child(2) > ul.nav-list { display: block; } </style> <script src="/blog/assets/js/vendor/lunr.min.js"></script> <script src="/blog/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Roadmap to RL | Notes</title> <meta name="generator" content="Jekyll v4.2.2" /> <meta property="og:title" content="Roadmap to RL" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Just messing around right now" /> <meta property="og:description" content="Just messing around right now" /> <link rel="canonical" href="http://localhost:4000/blog/deep-dive-notes/tactile-rl-notes/roadmap-rl.html" /> <meta property="og:url" content="http://localhost:4000/blog/deep-dive-notes/tactile-rl-notes/roadmap-rl.html" /> <meta property="og:site_name" content="Notes" /> <meta property="og:type" content="website" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="Roadmap to RL" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"Just messing around right now","headline":"Roadmap to RL","url":"http://localhost:4000/blog/deep-dive-notes/tactile-rl-notes/roadmap-rl.html"}</script> <!-- End Jekyll SEO tag --> <link rel="icon" href="data:,"> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } } }); </script> <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML"> </script> </head> <body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="/blog/" class="site-title lh-tight"> Notes </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Code Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/" class="nav-list-link">Code Notes</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/code-notes/how-to-pdb.html" class="nav-list-link">How-to PDB</a></li><li class="nav-list-item"><a href="/blog/code-notes/how-to-tmux.html" class="nav-list-link">How-to Tmux</a></li><li class="nav-list-item"><a href="/blog/code-notes/distributed-dl.html" class="nav-list-link">Distributed Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/image-augmentation.html" class="nav-list-link">Image Augmentation (Torchvision)</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Benchmarks category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/benchmark-notes/" class="nav-list-link">Benchmarks</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Robocasa category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/benchmark-notes/robocasa/" class="nav-list-link">Robocasa</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/code-notes/benchmark-notes/robocasa/paper.html" class="nav-list-link">Paper</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Libero category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/benchmark-notes/libero/" class="nav-list-link">Libero</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/code-notes/benchmark-notes/libero/paper.html" class="nav-list-link">Paper</a></li><li class="nav-list-item"><a href="/blog/code-notes/benchmark-notes/libero/code.html" class="nav-list-link">Code</a></li></ul></li><li class="nav-list-item"><a href="/blog/code-notes/benchmark-notes/robomimic.html" class="nav-list-link">Robomimic</a></li></ul></li><li class="nav-list-item"><a href="/blog/code-notes/python-env.html" class="nav-list-link">Python Environments</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in GROOT category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/groot/" class="nav-list-link">GROOT</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/code-notes/groot/code.html" class="nav-list-link">Code</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Isaac category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/isaac/" class="nav-list-link">Isaac</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/code-notes/isaac/setup.html" class="nav-list-link">Isaac Setup</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/doc_notes.html" class="nav-list-link">Isaac Gym Doc Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/gymenv-obs.html" class="nav-list-link">IsaacGymEnv Obs Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/gymenv-cam.html" class="nav-list-link">IsaacGymEnv Camera Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/gymenv-network.html" class="nav-list-link">IsaacGymEnv Network Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/gymenv-tacsl.html" class="nav-list-link">IsaacGymEnv Tacsl Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/gymenv-assets.html" class="nav-list-link">IsaacGymEnv Assets Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/gymenv-env.html" class="nav-list-link">IsaacGymEnv Env Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/gymenv-task.html" class="nav-list-link">IsaacGymEnv Task Notes</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/rl_games_integration.html" class="nav-list-link">RL Games Coupling</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaac/setup_isaacgymenvs.html" class="nav-list-link">IsaacGymEnvs Setup</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Cluster Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/cluster-notes/" class="nav-list-link">Cluster Notes</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/code-notes/cluster-notes/great-lakes.html" class="nav-list-link">Great Lakes Cluster</a></li><li class="nav-list-item"><a href="/blog/code-notes/cluster-notes/slurm-interactive.html" class="nav-list-link">SLURM Interactive</a></li><li class="nav-list-item"><a href="/blog/code-notes/cluster-notes/slurm.html" class="nav-list-link">SLURM</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Isaac Lab category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/code-notes/isaaclab/" class="nav-list-link">Isaac Lab</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/code-notes/isaaclab/setup.html" class="nav-list-link">Isaac Lab Setup</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaaclab/isaacsim-start.html" class="nav-list-link">Isaac Sim Python Start</a></li><li class="nav-list-item"><a href="/blog/code-notes/isaaclab/isaacsim-hello-world.html" class="nav-list-link">IsaacSim Core (Hello World)</a></li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Conference Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/conference-notes/" class="nav-list-link">Conference Notes</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in ICRA 2025 category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/conference-notes/icra-2025/" class="nav-list-link">ICRA 2025</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/workshop/beyond-pick-place.html" class="nav-list-link">Beyond Pick and Place Workshop</a></li><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/workshop/contact-rich.html" class="nav-list-link">Contact Rich Workshop</a></li><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/workshop/handy.html" class="nav-list-link">Handy Workshop</a></li><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/homework.html" class="nav-list-link">Homework</a></li><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/keynote-manipulation.html" class="nav-list-link">Manipulation Keynote</a></li><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/keynote-opt.html" class="nav-list-link">Optimization Control Keynote</a></li><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/workshop/neuro-symbolic.html" class="nav-list-link">Neuro-Symbolic Workshop</a></li><li class="nav-list-item"><a href="/blog/conference-notes/icra-2025/workshop/space.html" class="nav-list-link">Space Workshop</a></li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Class Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/class-notes/" class="nav-list-link">Class Notes</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in MATH 658: Geometric Mechanics category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/class-notes/00-Geometric-Mechanics/" class="nav-list-link">MATH 658: Geometric Mechanics</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in 658-Lectures category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/class-notes/00-Geometric-Mechanics/Lectures/" class="nav-list-link">658-Lectures</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/class-notes/00-Geometric-Mechanics/Lectures/08-27.html" class="nav-list-link">August 27</a></li><li class="nav-list-item"><a href="/blog/class-notes/00-Geometric-Mechanics/Lectures/09-03.html" class="nav-list-link">September 3</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Textbook category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/class-notes/00-Geometric-Mechanics/Textbook/" class="nav-list-link">Textbook</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/class-notes/00-Geometric-Mechanics/Textbook/diff-manifold.html" class="nav-list-link">Differentiable Manifold (2.2)</a></li><li class="nav-list-item"><a href="/blog/class-notes/00-Geometric-Mechanics/Textbook/variational-mech.html" class="nav-list-link">Variational Mechanics (1.2 - 1.3)</a></li><li class="nav-list-item"><a href="/blog/class-notes/00-Geometric-Mechanics/Textbook/vector-fields.html" class="nav-list-link">Vector Fields (2.1)</a></li></ul></li></ul></li><li class="nav-list-item"><a href="/blog/class-notes/01-Math-of-Bio-Networks/" class="nav-list-link">MATH 540: Mathematics for Biological Networks</a></li><li class="nav-list-item"><a href="/blog/class-notes/02-Online-Learning-Control/" class="nav-list-link">AEROSP 740: Online Learning for Control</a></li><li class="nav-list-item"><a href="/blog/class-notes/03-CVOPT-Control/" class="nav-list-link">ECE 598: Convex Optimization Methods in Control</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Sensorimotor Learning category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/class-notes/04-Computational-Sensorimotor-Learning/" class="nav-list-link">Sensorimotor Learning</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/class-notes/04-Computational-Sensorimotor-Learning/simple-decision.html" class="nav-list-link">1. Simple Decisions</a></li><li class="nav-list-item"><a href="/blog/class-notes/04-Computational-Sensorimotor-Learning/sequential-decision.html" class="nav-list-link">2. Sequential Decisions</a></li><li class="nav-list-item"><a href="/blog/class-notes/04-Computational-Sensorimotor-Learning/policy-grad.html" class="nav-list-link">3. Policy Gradients</a></li><li class="nav-list-item"><a href="/blog/class-notes/04-Computational-Sensorimotor-Learning/reward-function.html" class="nav-list-link">4. Reward Function</a></li><li class="nav-list-item"><a href="/blog/class-notes/04-Computational-Sensorimotor-Learning/learning-from-demo.html" class="nav-list-link">5. Learning Demos</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Unsupervised Learning category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/class-notes/05-Unsupervised-Learning/" class="nav-list-link">Unsupervised Learning</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/1_autoregressive.html" class="nav-list-link">1. Autoregressive</a></li><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/2_flow.html" class="nav-list-link">2. Flow</a></li><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/3_lvm.html" class="nav-list-link">3. Latent Variable Models</a></li><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/3a_lvm.html" class="nav-list-link">3a. LVM Papers</a></li><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/4_implicit_sample.html" class="nav-list-link">4. Implicit Models</a></li><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/5_diffusion.html" class="nav-list-link">5. Diffusion</a></li><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/5a_diffusion.html" class="nav-list-link">5a. Diffusion Papers</a></li><li class="nav-list-item"><a href="/blog/class-notes/05-Unsupervised-Learning/6_self_supervised.html" class="nav-list-link">6. Self-Supervised Learning</a></li></ul></li><li class="nav-list-item"><a href="/blog/class-notes/06-Flow-Matching/" class="nav-list-link">Flow Matching and Diffusion</a></li><li class="nav-list-item"><a href="/blog/class-notes/07-Deep-RL/" class="nav-list-link">Deep Reinforcement Learning</a></li><li class="nav-list-item"><a href="/blog/class-notes/08-Deep-Multitask-Learning/" class="nav-list-link">Deep Multi-Task and Meta Learning</a></li><li class="nav-list-item"><a href="/blog/class-notes/09-Algebraic-Techniques-Optimization/" class="nav-list-link">Algebraic Techniques for Optimization</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Deep Dive Ideas category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/deep-dive-notes/" class="nav-list-link">Deep Dive Ideas</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Debug Point ML category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/deep-dive-notes/debug-point-ml/" class="nav-list-link">Debug Point ML</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/deep-dive-notes/debug-point-ml/pointnet.html" class="nav-list-link">PointNet</a></li><li class="nav-list-item"><a href="/blog/deep-dive-notes/debug-point-ml/spatial-transformer.html" class="nav-list-link">Spatial Transformer Networks</a></li></ul></li><li class="nav-list-item"><a href="/blog/deep-dive-notes/limit-surface/" class="nav-list-link">Limit Surface Planner</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Tactile RL Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/deep-dive-notes/tactile-rl-notes/" class="nav-list-link">Tactile RL Notes</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/deep-dive-notes/tactile-rl-notes/fots.html" class="nav-list-link">FOTS</a></li><li class="nav-list-item"><a href="/blog/deep-dive-notes/tactile-rl-notes/roadmap-rl.html" class="nav-list-link">Roadmap to RL</a></li><li class="nav-list-item"><a href="/blog/deep-dive-notes/tactile-rl-notes/roadmap-tactile-rl.html" class="nav-list-link">Roadmap to Tactile RL</a></li><li class="nav-list-item"><a href="/blog/deep-dive-notes/tactile-rl-notes/sim2real-tactile-rl.html" class="nav-list-link">Sim2real Tactile RL</a></li><li class="nav-list-item"><a href="/blog/deep-dive-notes/tactile-rl-notes/tacsl.html" class="nav-list-link">TacSL</a></li><li class="nav-list-item"><a href="/blog/deep-dive-notes/tactile-rl-notes/taxim.html" class="nav-list-link">Taxim</a></li></ul></li></ul></li><li class="nav-list-item"><a href="/blog/paper-notes/" class="nav-list-link">Deep Dive Papers</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Judo Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/judo-notes/" class="nav-list-link">Judo Notes</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/judo-notes/taught.html" class="nav-list-link">Taught Moves</a></li><li class="nav-list-item"><a href="/blog/judo-notes/tolearn.html" class="nav-list-link">To Learn</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Kuka FRI Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/kuka-notes/" class="nav-list-link">Kuka FRI Notes</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/kuka-notes/code.html" class="nav-list-link">Code</a></li><li class="nav-list-item"><a href="/blog/kuka-notes/setup.html" class="nav-list-link">Setup FRI</a></li></ul></li><li class="nav-list-item"><a href="/blog/ml-git-gud-notes/" class="nav-list-link">ML (Git Gud) Resources</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in PhD Project Notes category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/project-notes/" class="nav-list-link">PhD Project Notes</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/project-notes/hand-notes.html" class="nav-list-link">Hand Notes</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Graph Insertion category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/project-notes/project1/" class="nav-list-link">Graph Insertion</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Lit Review (Graph Insertion) category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/project-notes/project1/lit_review/" class="nav-list-link">Lit Review (Graph Insertion)</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/project-notes/project1/lit_review/robopack.html" class="nav-list-link">Robopack</a></li><li class="nav-list-item"><a href="/blog/project-notes/project1/lit_review/tactile-control-extrinsic.html" class="nav-list-link">Extrinsic Contact Control</a></li></ul></li><li class="nav-list-item"><a href="/blog/project-notes/project1/math.html" class="nav-list-link">Math Notes</a></li><li class="nav-list-item"><a href="/blog/project-notes/project1/project.html" class="nav-list-link">Point RL</a></li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Prerequisites category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/prereq-notes/" class="nav-list-link">Prerequisites</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/prereq-notes/calc-variation.html" class="nav-list-link">Calculus of Variations - Chill</a></li><li class="nav-list-item"><a href="/blog/prereq-notes/calc-variation2.html" class="nav-list-link">Calculus of Variations - Serious</a></li><li class="nav-list-item"><a href="/blog/prereq-notes/groups.html" class="nav-list-link">GDL 1: Groups</a></li><li class="nav-list-item"><a href="/blog/prereq-notes/topology.html" class="nav-list-link">GDL 2: Topology</a></li><li class="nav-list-item"><a href="/blog/prereq-notes/manifolds.html" class="nav-list-link">GDL 3: Manifolds</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Quick Notes on Graphs category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/blog/graph-notes/" class="nav-list-link">Quick Notes on Graphs</a><ul class="nav-list"><li class="nav-list-item"><a href="/blog/graph-notes/advective-diff.html" class="nav-list-link">Advective Diffusion</a></li><li class="nav-list-item"><a href="/blog/graph-notes/beyond-wl.html" class="nav-list-link">Beyond WL-test</a></li><li class="nav-list-item"><a href="/blog/graph-notes/wl-test-gnn.html" class="nav-list-link">GNN WL-test</a></li><li class="nav-list-item"><a href="/blog/graph-notes/gnn-grad-flow.html" class="nav-list-link">GNN as Gradient Flow</a></li><li class="nav-list-item"><a href="/blog/graph-notes/gnn-pde.html" class="nav-list-link">GNNs as PDEs</a></li><li class="nav-list-item"><a href="/blog/graph-notes/graph-rewiring.html" class="nav-list-link">Graph Rewiring</a></li><li class="nav-list-item"><a href="/blog/graph-notes/latent-gnn.html" class="nav-list-link">Latent GNNs</a></li><li class="nav-list-item"><a href="/blog/graph-notes/neural-sheaf-diffusion.html" class="nav-list-link">Neural Sheaf Diffusion</a></li><li class="nav-list-item"><a href="/blog/graph-notes/deep-gnn.html" class="nav-list-link">Scaling GNNs</a></li><li class="nav-list-item"><a href="/blog/graph-notes/temporal-gnn.html" class="nav-list-link">Temporal GNNs</a></li></ul></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Notes" aria-label="Search Notes" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/blog/deep-dive-notes/">Deep Dive Ideas</a></li> <li class="breadcrumb-nav-list-item"><a href="/blog/deep-dive-notes/tactile-rl-notes/">Tactile RL Notes</a></li> <li class="breadcrumb-nav-list-item"><span>Roadmap to RL</span></li> </ol> </nav> <div id="main-content" class="main-content"> <main> <h1 id="roadmap-to-reinforcement-learning-for-manipulation"> <a href="#roadmap-to-reinforcement-learning-for-manipulation" class="anchor-heading" aria-labelledby="roadmap-to-reinforcement-learning-for-manipulation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Roadmap to Reinforcement Learning for Manipulation </h1> <h2 id="1-hard-code-approach"> <a href="#1-hard-code-approach" class="anchor-heading" aria-labelledby="1-hard-code-approach"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1. Hard-code Approach </h2> <p>Something we want to break down first is the process of doing manipulation/control:</p> <ul> <li>Observation: What can the robot sense?</li> <li>Action: What can the robot do?</li> <li>Policy: How does the robot generate actions based on observations?</li> </ul> <p>We need to have a starting point of how to do manipulation before moving to tactile sensors and tactile policies.</p> <p>If we wanted to write up a policy for a task like pick-and-place, where we want to pick up a desired object and place it down in a specific location, we can break it down into the following steps:</p> <ul> <li>Identify object in the scene and get its pose.</li> <li>Generate/Execute a trajectory to pick up the object.</li> <li>Identify the target location and Generate/Execute a trajectory to place the object.</li> <li>Let go of object and return to home pose.</li> </ul> <p>This seems very simple, and the observation is fairly simple as well. Using current state-of-the-art object detection algorithms + RGBD cameras, we can easily localize the object and use the manipulator to pick it up and place it down.</p> <p>However, notice that we divided up the policy into phases. This means that as the user, we have to do a lot of engineering and design for a certain manipulation task.</p> <p><strong>VERSATLITY</strong>: Something that people in robotics are very interested in is versatility. Can I just minimally give specifications to the robot and it takes in observations and figures out exactly what actions to take?</p> <p><strong>CAPABILITY</strong>: Another thing to consider is whether a robot can perform a difficult task with some versatility. We can sacrifice the generality of the policy if it can perform a specific task well.</p> <h2 id="2-control-approach"> <a href="#2-control-approach" class="anchor-heading" aria-labelledby="2-control-approach"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 2. Control approach </h2> <p>Control theory has been a long-standing field that robotics has relied on for decades. The basis of control theory is to use the dynamics of the system to generate actions based on observations. As in, we encode the physics of the system into the policy and use that to generate actions.</p> <p>In aerospace and automative, control theory has found a lot of success because of the ability to define a state space (position, velocity) and goal (desired position, desired velocity) and encode dynamics around that.</p> <p>For example, let our system be defined such that the origin \(g = \begin{bmatrix} 0 \\ ... \\ 0 \end{bmatrix}\) is the desired state. Then we define a general nonlinear system that takes in state \(x\) and action \(u\) such that:</p> \[\dot{x} = f(x, u)\] <p>where \(f\) is the dynamics of the system. Our goal is to then stabilize the system around the origin. The traditional way to do this is to write out our policy by hand and plug in the equations into our robot code.</p> <p>The current state-of-the-art approach and most widely used is to generate an optimization problem that finds actions that best minimize a cost function. This field is very deep and has a lot of theory behind it. One of the greatest benefits of control theory is getting guarantees from our systems and leveraging the deep insights from decades of research.</p> \[\min_{u_{0:T-1}} \sum_{t=0}^T C(x_{0:T}, u_{0:T-1}) \\ \text{s.t.} \quad x_{t+1} = f_\Delta(x_t, u_t)\] <p>While control is all great, there are a lot of limitations to applying it into the robotic manipulation setting.</p> <p><strong>ISSUES IN MANIPULATION:</strong></p> <ul> <li>If we wanted to sweep a pile of dust, how would we concretely define the state space of the dust particles? Without proper definition of state space, we cannot apply control theory or even designate what a goal is.</li> <li>The dynamics of a system that does manipulation is very difficult to work with: <ul> <li>Mathematicians work on what they finds interesting problems (things you can solve for and are nice).</li> <li>Control theory stems from mathematical roots and thus uses lots of assumptions to make the math easier to work with.</li> <li>The dynamics of a system with contact is very non-smooth in nature and cannot be easily solved using optimization (local methods) or through hand-written policies.</li> <li>In fact, the optimization problem using the dynamics of this system is NP-hard. <ul> <li>NP problems are problems that are non-deterministic but can be verified in polynomial time.</li> <li>As a reminder, NP-hard do not have to be NP. They just have to be as hard as an NP problem (NP-complete is reducible to said NP-hard problem).</li> </ul> </li> <li>One way of understanding this is that local actions around the state may or may not lead the state closer to a better solution. Non-local actions must be taken to get the optimal solution.</li> </ul> </li> <li>Normally the system is a fixed element that we specify. This restricts the versatility of our policy if we vary object shape, object mass, and object material.</li> </ul> <p><strong>NOTE</strong>: People try to accommodate for these issues by integrating deep learning in areas that are hard to work with. For example, we can learn latent sensor dynamics instead of the system dynamics itself or learn a model that is robust to object variation. However, it has been found that these approaches still have non-locality issues and have not found large adoption.</p> <p>As a recap, here are issues with control theory:</p> <ol> <li>Defining state space</li> <li>Non-smooth dynamics (non-local nature of manipulation)</li> <li>Rigidity of the system (fixed object shape, mass, material)</li> </ol> <p>One way to forego the issues of state space is to do input-output control. Let \(y = g(x)\) be the observation of the system. Then we can define a policy \(u = \pi(y)\) that takes in the observation and generates actions. In other words, we use the observations directly to generate actions without needing to define a state space. This is easier said than done.</p> <h2 id="3-learning-approach-bc"> <a href="#3-learning-approach-bc" class="anchor-heading" aria-labelledby="3-learning-approach-bc"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 3. Learning approach (BC) </h2> <p>Robot learning has been a rising topic in the past decade and has solidified itself as a key area of research. Everyone has hopped on the ML train. This crowd of people are completely separate from the control theory crowd, so their work does not try to solve the issues of control theory.</p> <p>The BC approach takes in a dataset of observations and actions, \(D = \{(y_i, u_i)\}_{i=1}^N\), and learns a policy \(\pi\) that maps observations to actions. In this dataset, we also assume that the actions are optimal given the observations. This approach foregoes the need for state space or dynamics and instead focuses on learning a mapping from observations to actions.</p> <p>Conceptually, we can see that given an observation (e.g. RGB image of the scene), we can output an action that is optimal for the task using a neural network. There are still some connections to control theory:</p> <ul> <li>We can actually view a well-trained BC policy as something that tries to stabilize the observations instead of the state space (like input-output control). <ul> <li>Observe that when BC policy sees the “goal” image, it outputs no actions. This is similar to stabilizing the system around the origin.</li> </ul> </li> <li>The “goal” observation is implicitly encoded in the dataset instead of explicitly defined. Additionally, this “goal” is not a fixed element and can vary in the same dataset (goal can be noisy).</li> </ul> <p>NOTE that the connection to control ends with Multi-task BC. Multi-task BC is when we have multiple tasks in the same dataset and the “goal” is specified as a language instruction.</p> <p>Here’s a diagram of a sample Multi-task policy BC neural network architecture:</p><pre><code class="language-mermaid">flowchart LR
    A(Image) --&gt; D[\Encoder Head/]
    B(Robot Joints) --&gt; E[\Encoder Head/]
    C(Language) --&gt; F[\Encoder Head/]
    D --&gt; G[Concat]
    E --&gt; G[Concat]
    F --&gt; G[Concat]
    G --&gt; H[MLP with ReLU]
    H --&gt; I[/Decoder Head\]
    I --&gt; J[Action]
</code></pre><p>Note that in here, the language instruction is used to “steer” the actions of a policy to perform a task from the dataset. This instruction is usually hard-coded into the dataset (No GPT robot unfortunately). TRI has shown that without language instruction (all null tokens), the policy still does things with objects. This gives the intuition that language embeddings are not describing goals but rather steering the policy towards a certain action distribution related to the task.</p> <p><strong>RELATION TO MANIPULATION</strong>: BC has gained a lot of traction in manipulation because a lot of tasks can just be performed by a human operator and easily replicated by the robot after training. The method is very versatile in terms of not having to really change the code for the policy. However, you do have to collect data for every task you want to perform. This is a big limitation of BC, as human data collection is very expensive and time-consuming.</p> <p><strong>ISSUES/LIMITATIONS</strong>: Current works are now trying to scale up BC and obtain a “GPT-moment” for robotics. However, there are still some limitations to BC:</p> <ol> <li>Language is not precise and can be ambiguous. “Move the red block a little bit” can mean different things to different people.</li> <li>Is it even possible to collect enough data for every task on every robot? This is highly debated, but the current consensus is that it is not possible to collect enough data for every task on every robot.</li> <li>Can our models even scale with this approach? Will training a larger model equate to better performance?</li> <li>Can BC do dexterous manipulation? Most tasks are simple pick-and-place tasks. The real question is whether BC can/should do things like in-hand manipulation, object balancing or pivoting, or cook a wok.</li> </ol> <p><strong>NOTE on Dexterous Manipulation</strong>: I honestly find that there’s a very blurry line on what is dexterous manipulation and what is not. Is cooking a wok really dexterous manipulation? We’re just moving a wok and spatula around. Many “dexterous manipulation” tasks are just pick-and-place or object grasping or moving objects around. It’s honestly becoming a catch-all term for any manipulation task that isn’t pick-and-place.</p> <h2 id="4-rl-approach-simulation"> <a href="#4-rl-approach-simulation" class="anchor-heading" aria-labelledby="4-rl-approach-simulation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 4. RL approach (Simulation) </h2> <p>Now reinforcement learning is not necessarily the next step up after BC, but it shows an interesting path forward. The jist of RL is the use of simulation to learn a policy. Can we get a robot to freely explore an environment and learn a policy that achieves a specified task? The big issue with RL is the sim2real gap. Can a robot learn a policy in simulation and transfer it to the real world?</p> <p>If we can close this sim2real gap, then we can leverage the versatility and capabilities of simulation and use RL as a means of leveraging simulation to train strong manipulation policies.</p> <p>Using simulation, we can completely forego the need for human data collection or at least tremendously reduce it.</p> <p><strong>RL OVERVIEW</strong>: The current state-of-the-art approach to robotics RL is to use PPO to train a neural network similar to the one used in BC in simulation. We can quickly summarize RL as follows:</p> \[\begin{equation} \max_{d} J(\theta + d) - J(\theta) \\ \text{s.t.} \quad \mathbb{E}_s \left[ D_{KL}(\pi_\theta(a \mid s) || \pi_{\theta + d}(a \mid s)) \right] \leq \epsilon \end{equation}\] <ul> <li>\(J(\theta)\) = \(\sum_{i=1}^N \sum_{t=1}^T \nabla_\theta \log \pi(a \mid s_t^t) A(s_t,a_t)\)</li> <li>\(A(s_t,a_t)\) = \(Q(s_t,a_t) - V(s_t)\)</li> </ul> <p>where we use an Actor-Critic method which contains an actor network and critic network (value function). The actor and critic can be assumed to have almost the same architecture until the very end where the actor outputs actions and the critic outputs a value. The actor generates actions on every rollout and is seen in this equation in \(a\) and \(\pi\) and the critic determines \(V(s_t)\) which will also determine the Q-function \(Q(s_t,a_t)\). We define the reward function based on the task we want to perform.</p> <p>If we just observed \(\nabla_\theta \log \pi(a \mid s_t^t) A(s_t,a_t)\) and set the advantage function to 1, we can see that this is the gradient of the log-likelihood of the actions taken. In other words, our policy gradient method is already taking gradients to maximize the likelihood of actions taken. This is a common method used in generative modeling to match a distribution. Once we add in the advantage function, we are now weighing which action distributions are better than others. In order for RL to train a good policy, we have to be able to use rewards to guide the policy towards actions that we know will help achieve the task. Without a good reward function, we could likelihood update our network towards a bad action distribution and possibly stay in that bad action distribution without hope of recovering.</p> <p><strong>STATE SPACE?</strong>: Based on this already, we can see that RL has a similar problem to control theory. How do you go about defining a reward function if there is no clear notion of state?</p> <ul> <li>Actually, you can normally simulate piles of objects and liquids in simulation, so you can define a reward function saying if a pile is in a reasonable configuration.</li> <li>However, this assumes that you can actually simulate at all.</li> <li>Based on this, simulation already requires you to define some sort of state for these weird objects, so we use that to define a reward function.</li> </ul> </main> <hr> <footer> <p class="text-small text-grey-dk-100 mb-0">By An Dang.</p> <div class="d-flex mt-2"> <p class="text-small text-grey-dk-000 mb-0"> <a href="https://github.com/dangthanhan507/dangthanhan507.github.io/blob/master/deep-dive-notes/tactile-rl-notes/roadmap-rl.md" id="edit-this-page">Edit this page on GitHub.</a> </p> </div> </footer> </div> </div> <div class="search-overlay"></div> </div> <script type="module"> import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11.6.0/dist/mermaid.esm.min.mjs'; var config = {} ; mermaid.initialize(config); mermaid.run({ querySelector: '.language-mermaid', }); </script> </body> </html>
